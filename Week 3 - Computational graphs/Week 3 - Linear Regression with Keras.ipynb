{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Week 3 - Linear Regression with Keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michelucci/zhaw-dlcourse-spring2019/blob/master/Week%203%20-%20Computational%20graphs/Week%203%20-%20Linear%20Regression%20with%20Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "aBLKB6Vu8ut3"
      },
      "cell_type": "markdown",
      "source": [
        "# Neural Networks and Deep Learning for Life Sciences and Health Applications - An introductory course about theoretical fundamentals, case studies and implementations in python and tensorflow"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ghs_W3B-8ut5"
      },
      "cell_type": "markdown",
      "source": [
        "(C) Umberto Michelucci 2018 - umberto.michelucci@gmail.com \n",
        "\n",
        "github repository: https://github.com/michelucci/zhaw-dlcourse-spring2019\n",
        "\n",
        "Spring Semester 2019"
      ]
    },
    {
      "metadata": {
        "id": "bDAhY3uwysaw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "import sklearn.linear_model as sk\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7h1Nh59zysa0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "boston = load_boston()\n",
        "features = np.array(boston.data)\n",
        "labels = np.array(boston.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vBzLyZy6ysa4",
        "colab_type": "code",
        "colab": {},
        "outputId": "930d4c64-d73c-4477-ede2-dc1f5dafbd13"
      },
      "cell_type": "code",
      "source": [
        "print(boston[\"DESCR\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".. _boston_dataset:\n",
            "\n",
            "Boston house prices dataset\n",
            "---------------------------\n",
            "\n",
            "**Data Set Characteristics:**  \n",
            "\n",
            "    :Number of Instances: 506 \n",
            "\n",
            "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
            "\n",
            "    :Attribute Information (in order):\n",
            "        - CRIM     per capita crime rate by town\n",
            "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
            "        - INDUS    proportion of non-retail business acres per town\n",
            "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
            "        - NOX      nitric oxides concentration (parts per 10 million)\n",
            "        - RM       average number of rooms per dwelling\n",
            "        - AGE      proportion of owner-occupied units built prior to 1940\n",
            "        - DIS      weighted distances to five Boston employment centres\n",
            "        - RAD      index of accessibility to radial highways\n",
            "        - TAX      full-value property-tax rate per $10,000\n",
            "        - PTRATIO  pupil-teacher ratio by town\n",
            "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
            "        - LSTAT    % lower status of the population\n",
            "        - MEDV     Median value of owner-occupied homes in $1000's\n",
            "\n",
            "    :Missing Attribute Values: None\n",
            "\n",
            "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
            "\n",
            "This is a copy of UCI ML housing dataset.\n",
            "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
            "\n",
            "\n",
            "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
            "\n",
            "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
            "prices and the demand for clean air', J. Environ. Economics & Management,\n",
            "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
            "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
            "pages 244-261 of the latter.\n",
            "\n",
            "The Boston house-price data has been used in many machine learning papers that address regression\n",
            "problems.   \n",
            "     \n",
            ".. topic:: References\n",
            "\n",
            "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
            "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TPEVIwc6ysa8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def normalize(dataset):\n",
        "    mu = np.mean(dataset, axis = 0)\n",
        "    sigma = np.std(dataset, axis = 0)\n",
        "    return (dataset-mu)/sigma"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mjPqYI3lysa-",
        "colab_type": "code",
        "colab": {},
        "outputId": "2bd95df7-b420-4542-8d6d-151a1b72fc4f"
      },
      "cell_type": "code",
      "source": [
        "n_training_samples = features.shape[0]\n",
        "n_dim = features.shape[1]\n",
        "\n",
        "print('The dataset has',n_training_samples,'training samples.')\n",
        "print('The dataset has',n_dim,'features.')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The dataset has 506 training samples.\n",
            "The dataset has 13 features.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gNgbXgoxysbC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_norm = normalize(features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9xXCgovdysbE",
        "colab_type": "code",
        "colab": {},
        "outputId": "3ae836d3-aa84-45f8-bbdf-c119da747a11"
      },
      "cell_type": "code",
      "source": [
        "print(features_norm.shape)\n",
        "print(labels.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(506, 13)\n",
            "(506,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "XPNqTSQlysbG",
        "colab_type": "code",
        "colab": {},
        "outputId": "423e2386-463b-4836-f26f-afe12f670752"
      },
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "rnd = np.random.rand(len(features_norm)) < 0.8\n",
        "\n",
        "train_x = features_norm[rnd]\n",
        "train_y = labels[rnd]\n",
        "test_x = features_norm[~rnd]\n",
        "test_y = labels[~rnd]\n",
        "\n",
        "print(train_x.shape)\n",
        "print(train_y.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(399, 13)\n",
            "(399,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2_VMpuphysbI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Network architecture (one neuron)"
      ]
    },
    {
      "metadata": {
        "id": "vykVkoeBysbJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Dense(1, input_shape=(13,)),\n",
        "    Activation('linear')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2NRjWWgdysbK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compiling the model"
      ]
    },
    {
      "metadata": {
        "id": "L1VE3T8QysbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics = ['mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VF2NCgKsysbM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fitting the model to the data"
      ]
    },
    {
      "metadata": {
        "id": "ydsVEZTvysbM",
        "colab_type": "code",
        "colab": {},
        "outputId": "1bf677d2-233e-4ba1-a4db-a3af7326a494"
      },
      "cell_type": "code",
      "source": [
        "model.fit(train_x, train_y, epochs=10000, batch_size=32, verbose = 0)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x13824d6a0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "C0HRN8A8ysbO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model"
      ]
    },
    {
      "metadata": {
        "id": "NEyqmgEuysbO",
        "colab_type": "code",
        "colab": {},
        "outputId": "3471de60-9f51-40aa-a135-31340763da73"
      },
      "cell_type": "code",
      "source": [
        "model.evaluate(test_x, test_y, batch_size=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "107/107 [==============================] - 0s 5us/sample - loss: 23.0263 - mean_squared_error: 23.0263\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[23.02628517150879, 23.026285]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}